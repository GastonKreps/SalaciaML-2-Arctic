{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score # Added roc_auc_score for AUC calculation\n",
    "import tensorflow as tf # Added for Keras initializer seed consistency\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # Suppress chained assignment warnings\n",
    "\n",
    "# Data and Model Paths (Ensure these paths are correct for your environment)\n",
    "DATA_FILE_PATH = 'UDASH-SML2A-Salinity.csv'  # Path to your UDASH data file\n",
    "MODEL_DIR = './model_output' # Directory to save/load models and history\n",
    "MODEL_CHECKPOINT_FILE = os.path.join(MODEL_DIR, \"model_checkpoint_seed.keras\")\n",
    "SAVED_MODEL_FILE_TEMPLATE = os.path.join(MODEL_DIR, 'salacia_qc_model_seed_{}.h5')\n",
    "HISTORY_FILE_TEMPLATE = os.path.join(MODEL_DIR, 'salacia_qc_model_seed_{}_history.npy')\n",
    "\n",
    "# Create model directory if it doesn't exist\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)\n",
    "    print(f\"Created directory: {MODEL_DIR}\")\n",
    "else:\n",
    "    print(f\"Directory {MODEL_DIR} already exists.\")\n",
    "\n",
    "# Define column names for features and target\n",
    "FEATURE_COLUMNS = [\n",
    "    'year', 'month', 'Longitude_[deg]', 'Latitude_[deg]', 'Depth_[m]',\n",
    "    'Salinity_[psu]',\n",
    "    'Salinity_gradient_s_d',\n",
    "    'Salinity_gradient_d_s'\n",
    "]\n",
    "TARGET_COLUMN_ORIGINAL = 'QF.2' # Original Quality Flag\n",
    "TARGET_COLUMN_TRADITIONAL = 'QF_trad' # Traditional Quality Flag (used for initial filtering)\n",
    "TARGET_COLUMN_PROCESSED = 'QF.2_processed' # Processed binary target for ML\n",
    "\n",
    "# Seed for reproducibility\n",
    "SEED = 567\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED) # Also set TensorFlow's seed for Keras operations\n",
    "tf_initializer_seed = 7 # Seed for Keras initializers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Step 1: Loading and Initial Preprocessing...\")\n",
    "try:\n",
    "    dtype_mapping = {\n",
    "        'Cruise': str, 'Station': str, 'Platform': str, 'Type': str,\n",
    "        'yyyy-mm-ddThh:mm': str, 'Source': str, 'DOI': str,\n",
    "        'WOD-Cruise-ID': str, 'Salinity_gradient_s_d': float,\n",
    "        'Salinity_gradient_d_s': float\n",
    "    }\n",
    "    data_df = pd.read_csv(DATA_FILE_PATH, dtype=dtype_mapping)\n",
    "    print(f\"Data loaded successfully from {DATA_FILE_PATH}. Shape: {data_df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Data file '{DATA_FILE_PATH}' not found. Please check the path.\")\n",
    "    # exit() # In a notebook, we might want to stop execution differently or allow user to fix path\n",
    "    raise\n",
    "\n",
    "# Remove rows with QF.2 flags 3 or 13\n",
    "initial_rows = len(data_df)\n",
    "data_df.drop(data_df[(data_df[TARGET_COLUMN_ORIGINAL].isin([3, 13]))].index, inplace=True)\n",
    "print(f\"Removed {initial_rows - len(data_df)} rows with QF.2 flags 3 or 13.\")\n",
    "\n",
    "# Identify profiles with suspect gradients or spikes\n",
    "all_suspect_gradient_spikes_df = data_df[data_df[TARGET_COLUMN_TRADITIONAL].isin([2, 4])]\n",
    "profiles_with_suspect_flags = data_df[data_df.Prof_no.isin(np.unique(all_suspect_gradient_spikes_df.Prof_no.unique()))].copy()\n",
    "print(f\"Identified {profiles_with_suspect_flags['Prof_no'].nunique()} profiles with suspect traditional flags (2 or 4).\")\n",
    "\n",
    "# Process QF.2 flags for these suspect profiles\n",
    "profiles_with_suspect_flags[TARGET_COLUMN_PROCESSED] = profiles_with_suspect_flags[TARGET_COLUMN_ORIGINAL].copy()\n",
    "profiles_with_suspect_flags[TARGET_COLUMN_PROCESSED].replace([2, 4, 12, 14], 1, inplace=True)\n",
    "profiles_with_suspect_flags[TARGET_COLUMN_PROCESSED][profiles_with_suspect_flags[TARGET_COLUMN_PROCESSED] != 1] = 0\n",
    "\n",
    "# Drop rows with placeholder values\n",
    "initial_rows_suspect = len(profiles_with_suspect_flags)\n",
    "profiles_with_suspect_flags.drop(\n",
    "    profiles_with_suspect_flags[(profiles_with_suspect_flags[FEATURE_COLUMNS] < -998.0).any(axis=1)].index,\n",
    "    inplace=True\n",
    ")\n",
    "print(f\"Removed {initial_rows_suspect - len(profiles_with_suspect_flags)} rows with placeholder values from suspect profiles.\")\n",
    "print(f\"Shape of profiles_with_suspect_flags after initial processing: {profiles_with_suspect_flags.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Further Filtering Based on Traditional Flag Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Step 2: Filtering Profiles by Traditional Flag Counts...\")\n",
    "# Count traditional flags (2 or 4) per profile\n",
    "trad_flag_counts = profiles_with_suspect_flags[\n",
    "    profiles_with_suspect_flags[TARGET_COLUMN_TRADITIONAL].isin([2, 4])\n",
    "].groupby('Prof_no').size()\n",
    "\n",
    "# Identify profiles with an excessive number of traditional flags (e.g., > 20)\n",
    "profiles_with_many_trad_flags = trad_flag_counts[trad_flag_counts > 20].index.tolist()\n",
    "print(f\"Number of profiles with more than 20 traditional flags: {len(profiles_with_many_trad_flags)}\")\n",
    "\n",
    "# Exclude these profiles\n",
    "filtered_data_df = profiles_with_suspect_flags[\n",
    "    ~profiles_with_suspect_flags['Prof_no'].isin(profiles_with_many_trad_flags)\n",
    "]\n",
    "print(f\"Original number of profiles (after initial QF filter): {profiles_with_suspect_flags['Prof_no'].nunique()}\")\n",
    "print(f\"Filtered number of profiles (after high trad-flag count filter): {filtered_data_df['Prof_no'].nunique()}\")\n",
    "\n",
    "# Focus on data points that were flagged by traditional methods\n",
    "bad_data_df = filtered_data_df[filtered_data_df[TARGET_COLUMN_TRADITIONAL] != 0].copy()\n",
    "\n",
    "# Standardize QF_trad for 'bad_data': treat flags 2 and 4 as 1 (bad)\n",
    "bad_data_df[TARGET_COLUMN_TRADITIONAL].replace([2, 4], 1, inplace=True)\n",
    "print(\"Value counts for QF_trad in 'bad_data_df' after standardization:\")\n",
    "print(bad_data_df[TARGET_COLUMN_TRADITIONAL].value_counts())\n",
    "print(f\"Shape of bad_data_df (data for ML model): {bad_data_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Splitting and Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Step 3: Splitting Data and Scaling Features...\")\n",
    "unique_profile_numbers = bad_data_df.Prof_no.unique()\n",
    "np.random.shuffle(unique_profile_numbers) # Shuffle profiles for random split\n",
    "\n",
    "# Split profile numbers for train, validation, and test sets\n",
    "train_prof_no, validate_prof_no, test_prof_no = np.split(\n",
    "    unique_profile_numbers,\n",
    "    [int(len(unique_profile_numbers) * 0.7), int(len(unique_profile_numbers) * 0.95)]\n",
    ")\n",
    "\n",
    "print(f\"Number of profiles for training: {len(train_prof_no)}\")\n",
    "print(f\"Number of profiles for validation: {len(validate_prof_no)}\")\n",
    "print(f\"Number of profiles for testing: {len(test_prof_no)}\")\n",
    "\n",
    "# Create dataframes for each set\n",
    "train_df = bad_data_df[bad_data_df['Prof_no'].isin(train_prof_no.tolist())]\n",
    "validation_df = bad_data_df[bad_data_df['Prof_no'].isin(validate_prof_no.tolist())]\n",
    "test_df = bad_data_df[bad_data_df['Prof_no'].isin(test_prof_no.tolist())]\n",
    "\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Validation data shape: {validation_df.shape}\")\n",
    "print(f\"Test data shape: {test_df.shape}\")\n",
    "\n",
    "# Prepare for scaling\n",
    "X_train_features = train_df[FEATURE_COLUMNS].reset_index(drop=True)\n",
    "X_val_features = validation_df[FEATURE_COLUMNS].reset_index(drop=True)\n",
    "X_test_features = test_df[FEATURE_COLUMNS].reset_index(drop=True)\n",
    "\n",
    "y_train = train_df[TARGET_COLUMN_PROCESSED]\n",
    "y_val = validation_df[TARGET_COLUMN_PROCESSED]\n",
    "y_test = test_df[TARGET_COLUMN_PROCESSED]\n",
    "\n",
    "# Initialize and fit scaler ONLY on training data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_features.values)\n",
    "\n",
    "# Apply transform to all sets\n",
    "X_train_scaled = scaler.transform(X_train_features.values)\n",
    "X_val_scaled = scaler.transform(X_val_features.values)\n",
    "X_test_scaled = scaler.transform(X_test_features.values)\n",
    "\n",
    "# Convert scaled arrays back to DataFrames\n",
    "X_train = pd.DataFrame(X_train_scaled, columns=FEATURE_COLUMNS)\n",
    "X_val = pd.DataFrame(X_val_scaled, columns=FEATURE_COLUMNS)\n",
    "X_test = pd.DataFrame(X_test_scaled, columns=FEATURE_COLUMNS)\n",
    "\n",
    "print(\"Features scaled successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Building and Training (or Loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Step 4: Model Building and Training (or Loading)...\")\n",
    "saved_model_file = SAVED_MODEL_FILE_TEMPLATE.format(SEED)\n",
    "history_file = HISTORY_FILE_TEMPLATE.format(SEED)\n",
    "\n",
    "if not os.path.exists(saved_model_file):\n",
    "    print(f\"No pre-trained model found at {saved_model_file}. Training a new model.\")\n",
    "    input_dim = X_train.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, kernel_initializer=initializers.glorot_normal(seed=tf_initializer_seed), input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dense(32, kernel_initializer=initializers.glorot_normal(seed=tf_initializer_seed), activation='relu'))\n",
    "    model.add(Dense(16, kernel_initializer=initializers.glorot_normal(seed=tf_initializer_seed), activation='relu'))\n",
    "    model.add(Dense(8, kernel_initializer=initializers.glorot_normal(seed=tf_initializer_seed), activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer=initializers.glorot_normal(seed=tf_initializer_seed), activation='sigmoid'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    # Compile and train\n",
    "    epochs = 1500\n",
    "    batch_size = 16384\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    checkpoint = ModelCheckpoint(MODEL_CHECKPOINT_FILE, monitor='val_loss', verbose=0, save_best_only=True, mode='min')\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    history_obj = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1, \n",
    "                        validation_data=(X_val, y_val), shuffle=True, callbacks=callbacks_list)\n",
    "\n",
    "    # Load the best model saved by checkpoint for further use and saving final state\n",
    "    print(f\"Loading best model from checkpoint: {MODEL_CHECKPOINT_FILE}\")\n",
    "    model = load_model(MODEL_CHECKPOINT_FILE) \n",
    "    model.save(saved_model_file) # Save the best model to the final path\n",
    "    np.save(history_file, history_obj.history)\n",
    "    history = history_obj.history\n",
    "    print(f\"Model and history saved for seed {SEED}.\")\n",
    "else:\n",
    "    print(f\"Loading pre-trained model from {saved_model_file}...\")\n",
    "    model = load_model(saved_model_file)\n",
    "    if os.path.exists(history_file):\n",
    "        history = np.load(history_file, allow_pickle=True).item()\n",
    "        print(\"Model history loaded.\")\n",
    "    else:\n",
    "        history = None\n",
    "        print(\"Warning: Model history file not found. Loss plot will not be generated.\")\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Step 5: Model Evaluation...\")\n",
    "\n",
    "# Plot loss if history is available\n",
    "if history:\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.plot(history['loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Model Loss (Seed: {SEED})')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(MODEL_DIR, f'model_loss_seed_{SEED}.png'))\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Skipping loss plot as history is not available.\")\n",
    "\n",
    "\n",
    "# Plot ROC curve on validation data to determine the best threshold\n",
    "y_pred_val_proba = model.predict(X_val)[:, 0]\n",
    "fpr, tpr, thresholds = roc_curve(y_val, y_pred_val_proba)\n",
    "gmeans = np.sqrt(tpr * (1 - fpr)) # Geometric Mean for finding best threshold\n",
    "ix = np.argmax(gmeans)\n",
    "best_threshold = thresholds[ix]\n",
    "print(f\"Best Threshold based on G-Mean (Validation Set): {best_threshold:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label=f'No Skill (AUC = 0.5)')\n",
    "plt.plot(fpr, tpr, marker='.', label=f'Validation ROC (AUC = {roc_auc_score(y_val, y_pred_val_proba):.2f})')\n",
    "plt.scatter(fpr[ix], tpr[ix], marker='o', s=100, color='black', label=f'Best Threshold ({best_threshold:.2f})')\n",
    "plt.title(f'ROC Curve (Validation Set - Seed: {SEED})')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(MODEL_DIR, f'roc_curve_validation_seed_{SEED}.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Predictions on Test Set and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Step 6: Predictions on Test Set and Analysis...\")\n",
    "# Make predictions on the test dataset using probabilities\n",
    "predictions_test_proba = model.predict(X_test)[:, 0]\n",
    "\n",
    "# Apply the best threshold found on the validation set\n",
    "predictions_test_binary = (predictions_test_proba >= best_threshold).astype(int)\n",
    "\n",
    "# Add ML predictions to the original test_df (before scaling for feature columns)\n",
    "test_df_analysis = test_df.copy() # Use the unscaled test_df for adding predictions\n",
    "test_df_analysis['ML_Prediction'] = predictions_test_binary\n",
    "\n",
    "# Process QF_trad: set all values to 0 except 1 (bad) for comparison\n",
    "test_df_analysis.loc[:, TARGET_COLUMN_TRADITIONAL][test_df_analysis[TARGET_COLUMN_TRADITIONAL] != 1] = 0\n",
    "\n",
    "# Create ML_TQF column (merged ML prediction with traditional flag)\n",
    "test_df_analysis['ML_TQF'] = test_df_analysis['ML_Prediction'] * test_df_analysis[TARGET_COLUMN_TRADITIONAL]\n",
    "\n",
    "# y_true_test is y_test (TARGET_COLUMN_PROCESSED for the test set)\n",
    "y_true_test = y_test \n",
    "\n",
    "# Confusion matrix for ML_TQF vs True Flags\n",
    "cm_ml_tqf = confusion_matrix(y_true_test, test_df_analysis['ML_TQF'])\n",
    "\n",
    "# Confusion matrix for Traditional Flags vs True Flags\n",
    "cm_traditional = confusion_matrix(y_true_test, test_df_analysis[TARGET_COLUMN_TRADITIONAL])\n",
    "\n",
    "\n",
    "# Plot ML_TQF Confusion Matrix\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm_ml_tqf, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=['Predicted Good', 'Predicted Bad'],\n",
    "            yticklabels=['Actual Good', 'Actual Bad'])\n",
    "plt.title(f'ML + Traditional Flag (ML_TQF) Confusion Matrix (Seed: {SEED})')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(MODEL_DIR, f'confusion_matrix_ml_tqf_seed_{SEED}.png'))\n",
    "plt.show()\n",
    "\n",
    "# Plot Traditional Confusion Matrix\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm_traditional, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=['Predicted Good', 'Predicted Bad'],\n",
    "            yticklabels=['Actual Good', 'Actual Bad'])\n",
    "plt.title(f'Traditional Flag Only Confusion Matrix (Seed: {SEED})')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(MODEL_DIR, f'confusion_matrix_traditional_seed_{SEED}.png'))\n",
    "plt.show()\n",
    "\n",
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.x.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
plt.savefig(os.path.join(MODEL_DIR, f'confusion_matrix_traditional_seed_{SEED}.png'))
plt.show()
